# Speech-Emotion-Recognition-Using-Deep-Learning
This project focuses on detecting human emotions from speech using deep learning techniques. We trained a neural network on the RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset to classify emotional states.
## Features
### Audio-based emotion recognition

## Deep learning model (e.g., CNN + LSTM or custom ANN)

### Trained on RAVDESS dataset

### Emotion classes: Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised

### Built with Python and PyTorch

## Model Overview
### Input: MFCC features extracted from .wav files

### Model: Sequential deep learning model (custom ANN or CNN-LSTM)

###Output: One of the 8 emotion classes

## Dataset: RAVDESS
### Download link: RAVDESS on kaggle

Contains 24 professional actors vocalizing two lexically-matched statements in a neutral North American accent.

### Tech Stack
Python

PyTorch / TensorFlow

Librosa (for audio feature extraction)

Scikit-learn

Matplotlib / Seaborn
